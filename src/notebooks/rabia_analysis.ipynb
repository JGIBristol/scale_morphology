{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a5e758",
   "metadata": {},
   "source": [
    "Scale Analysis Example\n",
    "====\n",
    "Using scales from Rabia Sevil\n",
    "\n",
    "We'll read the LIF files, try to segment them out (either just by thresholding or by using a pretrained model) and then run EFA to summarise their shape variation.\n",
    "\n",
    "Read in the scales\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cfc20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a321b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "parent_dir = pathlib.Path(\"~/zebrafish_rdsf/Rabia/SOST scales\").expanduser()\n",
    "assert parent_dir.exists()\n",
    "\n",
    "scale_dirs = tuple(d for d in parent_dir.glob(\"*\") if not d.stem in {\".DS_Store\", \"TIFs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e648093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scale_morphology.scales import read\n",
    "\n",
    "scale_dir = scale_dirs[1]\n",
    "scale_paths = scale_dir.glob(\"*.lif\")\n",
    "path = next(scale_paths)\n",
    "print(path)\n",
    "\n",
    "names, images = zip(*read.read_lif(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import textwrap\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def factor_int(n):\n",
    "    val = math.ceil(math.sqrt(n))\n",
    "    val2 = int(n / val)\n",
    "    while val2 * val != float(n):\n",
    "        val -= 1\n",
    "        val2 = int(n / val)\n",
    "    return val, val2\n",
    "\n",
    "\n",
    "def plot_imgs(images, **plot_kw):\n",
    "    global titles\n",
    "\n",
    "    n_figs = factor_int(len(images))\n",
    "\n",
    "    fig, axes = plt.subplots(*n_figs, figsize=[3 * x for x in n_figs])\n",
    "    for axis, img, title in zip(tqdm(axes.flat), images, titles):\n",
    "        axis.imshow(img, **plot_kw)\n",
    "        axis.set_title(title)\n",
    "        axis.set_axis_off()\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "titles = [\"\\n\".join(textwrap.wrap(name, width=10)) for name in names]\n",
    "if plot:\n",
    "    plot_imgs(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651271e",
   "metadata": {},
   "source": [
    "Segment them\n",
    "----\n",
    "Now that we have read the scales into memory, we want to threshold them out.\n",
    "There aren't that many, so we could probably just do this by hand, but I don't have a mouse right now so I'm going to try to do it using computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf3ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "So I can continue with the analysis while some stuff downloads, let's pretend that these are the finished masks...\n",
    "\"\"\"\n",
    "import pathlib\n",
    "import tifffile\n",
    "mask_dir = pathlib.Path(\"segmentation_stuff/masks\")\n",
    "\n",
    "masks = [tifffile.imread(path) for path in tqdm(list(mask_dir.glob(\"*.tif\")))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5796e8",
   "metadata": {},
   "source": [
    "Elliptical Fourier Analysis\n",
    "----\n",
    "We'll summarise their shapes using Elliptical Fourier Analysis (EFA)\n",
    "<a name=\"cite_ref-1\"></a><sup>[1]</sup>\n",
    "<a name=\"cite_ref-2\"></a><sup>[2]</sup>,\n",
    "which basically decomposes the boundary into sums of ellipses.\n",
    "The coefficients (strength and direction of each size of ellipse) tell us about the shape of the object.\n",
    "There's a demonstration of how this works [here](https://reinvantveer.github.io/2019/07/12/elliptical_fourier_analysis.html).\n",
    "\n",
    "Our edge is constructed as:\n",
    "\n",
    "\\begin{aligned}\n",
    "x(t) &= a_0 + \\sum_{n=1}^{N} \\big[a_n \\cos(n t) + b_n \\sin(n t)\\big],\\\\\n",
    "y(t) &= c_0 + \\sum_{n=1}^{N} \\big[c_n \\cos(n t) + d_n \\sin(n t)\\big],\n",
    "\\qquad t \\in [0, 2\\pi].\n",
    "\\end{aligned}\n",
    "\n",
    "with:\n",
    "\n",
    "\\begin{aligned}\n",
    "a_0 = \\frac{1}{2\\pi}\\int_{0}^{2\\pi} x(t)\\,dt,\\qquad\n",
    "c_0 = \\frac{1}{2\\pi}\\int_{0}^{2\\pi} y(t)\\,dt.\n",
    "\\end{aligned}\n",
    "\n",
    "\\begin{aligned}\n",
    "a_n &= \\frac{1}{\\pi}\\int_{0}^{2\\pi} x(t)\\cos(n t)\\,dt, &\n",
    "b_n &= \\frac{1}{\\pi}\\int_{0}^{2\\pi} x(t)\\sin(n t)\\,dt,\\\\\n",
    "c_n &= \\frac{1}{\\pi}\\int_{0}^{2\\pi} y(t)\\cos(n t)\\,dt, &\n",
    "d_n &= \\frac{1}{\\pi}\\int_{0}^{2\\pi} y(t)\\sin(n t)\\,dt.\n",
    "\\end{aligned}\n",
    "\n",
    "possibly up to some factors of $2\\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40641cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\"\"\"\n",
    "Perform EFA on the scales and plot the reconstruction\n",
    "\"\"\"\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from scale_morphology.scales import efa, errors, segmentation\n",
    "\n",
    "n_edge_points = 200\n",
    "order = 50\n",
    "\n",
    "coeffs = []\n",
    "for scale in tqdm(masks):\n",
    "    # Hack - lots of them are broken\n",
    "    # This doesn't even work as a hack. oh well\n",
    "    scale = segmentation._largest_connected_component(scale)\n",
    "    scale = binary_fill_holes(scale, structure=np.ones((3, 3)))\n",
    "    scale = (scale * 255).astype(np.uint8)\n",
    "    try:\n",
    "        coeffs.append(efa.coefficients(scale, n_edge_points, order))\n",
    "    except errors.BadImgError as e:\n",
    "        coeffs.append(np.ones((order, 4)) * np.nan)\n",
    "        print(f\"\\nError processing scale: {e}. NaN coeffs\")\n",
    "coeffs = np.stack(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faacf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_indices = ~np.isnan(coeffs).any(axis=(1, 2))\n",
    "\n",
    "good_mask_names = np.array([path.name for path in tqdm(list(mask_dir.glob(\"*.tif\")))])[\n",
    "    good_indices\n",
    "]\n",
    "good_coeffs = coeffs[good_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c530ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "images = np.array(masks)[good_indices]\n",
    "flat_coeffs = good_coeffs.reshape((good_coeffs.shape[0], -1))\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "transformed_coeffs = np.ascontiguousarray(pca.fit_transform(flat_coeffs))\n",
    "\n",
    "good_imgs = [\n",
    "    tifffile.imread(f\"segmentation_stuff/masks/{pathlib.Path(p).name}\")\n",
    "    for p in tqdm(good_mask_names)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scale_morphology.scales import dashboard\n",
    "\n",
    "embeddable_imgs = [\n",
    "    dashboard.embeddable_image(i.astype(np.uint8) * 255) for i in tqdm(good_imgs)\n",
    "]\n",
    "\n",
    "\n",
    "colours = []\n",
    "\n",
    "\n",
    "def _colour(name):\n",
    "    name = name.lower()\n",
    "    if \"hom\" in name:\n",
    "        if \"ontogenetic\" in name:\n",
    "            return 0\n",
    "        return 1\n",
    "    if \"ontogenetic\" in name:\n",
    "        return 2\n",
    "    return 3\n",
    "\n",
    "\n",
    "for name in good_mask_names:\n",
    "    colours.append(str(_colour(name)))\n",
    "\n",
    "dashboard_df = pd.DataFrame(transformed_coeffs, columns=[\"x\", \"y\"])\n",
    "dashboard_df[\"image\"] = embeddable_imgs\n",
    "dashboard_df[\"colour\"] = colours\n",
    "dashboard_df[\"name\"] = good_mask_names\n",
    "\n",
    "dashboard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a4e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, save\n",
    "from bokeh.models import ColumnDataSource, HoverTool, CategoricalColorMapper\n",
    "from bokeh.resources import INLINE\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "factors = np.unique(dashboard_df[\"colour\"])\n",
    "mapper = CategoricalColorMapper(factors=factors, palette=f\"Category10_4\")\n",
    "\n",
    "datasource = ColumnDataSource(dashboard_df)\n",
    "fig = figure(\n",
    "    title=\"Test\", width=800, height=800, tools=\"pan, wheel_zoom, box_zoom, reset\"\n",
    ")\n",
    "\n",
    "fig.add_tools(\n",
    "    (\n",
    "        HoverTool(\n",
    "            tooltips=\"\"\"\n",
    "<div>\n",
    "    <div>\n",
    "        <img src=\"@image\" style=\"float: left; margin: 5px 5px 5px 5px;\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <span style=\"font-size: 17px; font-weight: bold;\">@name</span>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.scatter(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    source=datasource,\n",
    "    size=4,\n",
    "    color={\"field\": \"colour\", \"transform\": mapper},\n",
    "    legend_field=\"colour\",\n",
    ")\n",
    "\n",
    "for i, colour_value in enumerate(np.unique(dashboard_df[\"colour\"])):\n",
    "    group_points = dashboard_df[dashboard_df[\"colour\"] == colour_value][\n",
    "        [\"x\", \"y\"]\n",
    "    ].values\n",
    "\n",
    "    if len(group_points) >= 3:\n",
    "        hull = ConvexHull(group_points)\n",
    "\n",
    "        vertices = group_points[hull.vertices]\n",
    "\n",
    "        # Close the polygon by adding the first point at the end\n",
    "        vertices = np.vstack([vertices, vertices[0]])\n",
    "\n",
    "        hull_color = mapper.palette[i % len(mapper.palette)]\n",
    "        fig.patch(\n",
    "            x=vertices[:, 0],\n",
    "            y=vertices[:, 1],\n",
    "            alpha=0.2,\n",
    "            line_color=hull_color,\n",
    "            line_width=2,\n",
    "            fill_color=hull_color,\n",
    "        )\n",
    "\n",
    "filename = \"test_dashboard.html\"\n",
    "save(\n",
    "    fig,\n",
    "    filename=filename,\n",
    "    title=pathlib.Path(filename.replace(\".html\", \"\")).name,\n",
    "    resources=INLINE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scale_morphology.scripts.plotting import interpret_dimensions\n",
    "\n",
    "interpret_dimensions._plot_pca_importance(\n",
    "    good_coeffs, np.zeros(good_coeffs.shape[0], dtype=bool)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [np.sum(m) / 255 for m in tqdm(np.array(masks)[good_indices])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21ad45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sizes, transformed_coeffs[:, 0], \".\")\n",
    "plt.xlabel(\"Scale Size (pixels?)\")\n",
    "plt.ylabel(\"PC1\")\n",
    "plt.title(\"The first principal component corresponds tells us about size\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_dir = pathlib.Path(\"rabia\")\n",
    "plot_dir.mkdir(exist_ok=True)\n",
    "plt.savefig(plot_dir /\"sizes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5432235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "from skimage.draw import polygon\n",
    "\n",
    "\n",
    "def convex_hull_mask(mask_bool):\n",
    "    \"\"\"Rasterize the convex hull of foreground pixels into a mask.\"\"\"\n",
    "    ys, xs = np.nonzero(mask_bool)\n",
    "    pts = np.stack([xs, ys], axis=1)  # (x, y)\n",
    "    if pts.shape[0] < 3:\n",
    "        return mask_bool.copy(), 0.0\n",
    "    hull = ConvexHull(pts)\n",
    "    hull_xy = pts[hull.vertices]\n",
    "    rr, cc = polygon(hull_xy[:, 1], hull_xy[:, 0], shape=mask_bool.shape)\n",
    "    hull_mask = np.zeros_like(mask_bool, dtype=bool)\n",
    "    hull_mask[rr, cc] = True\n",
    "    return hull_mask, hull.volume  # hull.volume is 2D area\n",
    "\n",
    "\n",
    "def concavity_metrics(mask_bool):\n",
    "    area = float(mask_bool.sum())\n",
    "    if area == 0:\n",
    "        return dict(\n",
    "            solidity=np.nan,\n",
    "            concavity_frac=np.nan,\n",
    "            dent_max=np.nan,\n",
    "            dent_mean=np.nan,\n",
    "            dent_max_norm=np.nan,\n",
    "            concavity_area=np.nan,\n",
    "        )\n",
    "\n",
    "    hull_mask, hull_area = convex_hull_mask(mask_bool)\n",
    "    if hull_area == 0:\n",
    "        return dict(\n",
    "            solidity=np.nan,\n",
    "            concavity_frac=np.nan,\n",
    "            dent_max=np.nan,\n",
    "            dent_mean=np.nan,\n",
    "            dent_max_norm=np.nan,\n",
    "            concavity_area=np.nan,\n",
    "        )\n",
    "\n",
    "    # Area-based concavity\n",
    "    solidity = area / hull_area\n",
    "    return 1.0 - solidity\n",
    "\n",
    "\n",
    "concavity = [concavity_metrics(m == 255) for m in tqdm(np.array(masks)[good_indices])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3703b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(concavity, transformed_coeffs[:, 1], \".\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576aad49",
   "metadata": {},
   "source": [
    "[^1](#cite_ref-1):  F. P. Kuhl and C. R. Giardina, ‘Elliptic Fourier features of a closed contour’, Computer Graphics and Image Processing, vol. 18, no. 3, pp. 236–258, Mar. 1982, doi: 10.1016/0146-664x(82)90034-x. \n",
    "\n",
    "[^2](#cite_ref-2): N. MacLeod, 'PalaeoMath 101 part 25: the centre cannot hold II: Elliptic fourier\n",
    "analysis.' Palaeontol. Assoc. Newslett. 79, 29–43, 2012 http://go.palass.org/65a."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scale-morphology (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
