{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a5e758",
   "metadata": {},
   "source": [
    "Scale Analysis Example\n",
    "====\n",
    "Using scales from Rabia Sevil\n",
    "\n",
    "We'll read the LIF files, try to segment them out (either just by thresholding or by using a pretrained model) and then run EFA to summarise their shape variation.\n",
    "\n",
    "Read in the scales\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cfc20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a321b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "parent_dir = pathlib.Path(\"~/zebrafish_rdsf/Rabia/SOST scales\").expanduser()\n",
    "assert parent_dir.exists()\n",
    "\n",
    "scale_dirs = tuple(d for d in parent_dir.glob(\"*\") if not d.stem in {\".DS_Store\", \"TIFs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e648093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scale_morphology.scales import read\n",
    "\n",
    "scale_dir = scale_dirs[1]\n",
    "scale_paths = scale_dir.glob(\"*.lif\")\n",
    "path = next(scale_paths)\n",
    "print(path)\n",
    "\n",
    "names, images = zip(*read.read_lif(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import textwrap\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def factor_int(n):\n",
    "    val = math.ceil(math.sqrt(n))\n",
    "    val2 = int(n / val)\n",
    "    while val2 * val != float(n):\n",
    "        val -= 1\n",
    "        val2 = int(n / val)\n",
    "    return val, val2\n",
    "\n",
    "\n",
    "def plot_imgs(images, **plot_kw):\n",
    "    global titles\n",
    "\n",
    "    n_figs = factor_int(len(images))\n",
    "\n",
    "    fig, axes = plt.subplots(*n_figs, figsize=[3 * x for x in n_figs])\n",
    "    for axis, img, title in zip(tqdm(axes.flat), images, titles):\n",
    "        axis.imshow(img, **plot_kw)\n",
    "        axis.set_title(title)\n",
    "        axis.set_axis_off()\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "titles = [\"\\n\".join(textwrap.wrap(name, width=10)) for name in names]\n",
    "if plot:\n",
    "    plot_imgs(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651271e",
   "metadata": {},
   "source": [
    "Segment them\n",
    "----\n",
    "Now that we have read the scales into memory, we want to threshold them out.\n",
    "There aren't that many, so we could probably just do this by hand, but I don't have a mouse right now so I'm going to try to do it using computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf3ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "So I can continue with the analysis while some stuff downloads, let's pretend that these are the finished masks...\n",
    "\"\"\"\n",
    "import pathlib\n",
    "import tifffile\n",
    "mask_dir = pathlib.Path(\"segmentation_stuff/masks\")\n",
    "\n",
    "masks = [tifffile.imread(path) for path in tqdm(list(mask_dir.glob(\"*.tif\")))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5796e8",
   "metadata": {},
   "source": [
    "Elliptical Fourier Analysis\n",
    "----\n",
    "We'll summarise their shapes using Elliptical Fourier Analysis (EFA)\n",
    "<a name=\"cite_ref-1\"></a><sup>[1]</sup>\n",
    "<a name=\"cite_ref-2\"></a><sup>[2]</sup>,\n",
    "which basically decomposes the boundary into sums of ellipses.\n",
    "The coefficients (strength and direction of each size of ellipse) tell us about the shape of the object.\n",
    "There's a demonstration of how this works [here](https://reinvantveer.github.io/2019/07/12/elliptical_fourier_analysis.html).\n",
    "\n",
    "Our edge is constructed as:\n",
    "\n",
    "\\begin{aligned}\n",
    "x(t) &= a_0 + \\sum_{n=1}^{N} \\big[a_n \\cos(n t) + b_n \\sin(n t)\\big],\\\\\n",
    "y(t) &= c_0 + \\sum_{n=1}^{N} \\big[c_n \\cos(n t) + d_n \\sin(n t)\\big],\n",
    "\\qquad t \\in [0, 2\\pi].\n",
    "\\end{aligned}\n",
    "\n",
    "with:\n",
    "\n",
    "\\begin{aligned}\n",
    "a_0 = \\frac{1}{2\\pi}\\int_{0}^{2\\pi} x(t)\\,dt,\\qquad\n",
    "c_0 = \\frac{1}{2\\pi}\\int_{0}^{2\\pi} y(t)\\,dt.\n",
    "\\end{aligned}\n",
    "\n",
    "\\begin{aligned}\n",
    "a_n &= \\frac{1}{\\pi}\\int_{0}^{2\\pi} x(t)\\cos(n t)\\,dt, &\n",
    "b_n &= \\frac{1}{\\pi}\\int_{0}^{2\\pi} x(t)\\sin(n t)\\,dt,\\\\\n",
    "c_n &= \\frac{1}{\\pi}\\int_{0}^{2\\pi} y(t)\\cos(n t)\\,dt, &\n",
    "d_n &= \\frac{1}{\\pi}\\int_{0}^{2\\pi} y(t)\\sin(n t)\\,dt.\n",
    "\\end{aligned}\n",
    "\n",
    "possibly up to some factors of $2\\pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40641cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\"\"\"\n",
    "Perform EFA on the scales and plot the reconstruction\n",
    "\"\"\"\n",
    "import pathlib\n",
    "import importlib\n",
    "\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from scale_morphology.scales import efa, errors, segmentation\n",
    "\n",
    "n_edge_points = 200\n",
    "order = 50\n",
    "\n",
    "masks = [255*tifffile.imread(f).astype(np.uint8) for f in tqdm(list((pathlib.Path(\"segmentation_stuff2\")/\"masks\").glob(\"*.tif\")))]\n",
    "\n",
    "coeffs = []\n",
    "for scale in tqdm(masks):\n",
    "    try:\n",
    "        coeffs.append(efa.coefficients(scale, n_edge_points, order))\n",
    "    except errors.BadImgError as e:\n",
    "        coeffs.append(np.ones((order, 4)) * np.nan)\n",
    "        print(f\"\\nError processing scale: {e}. NaN coeffs\")\n",
    "coeffs = np.stack(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faacf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_indices = ~np.isnan(coeffs).any(axis=(1, 2))\n",
    "\n",
    "mask_dir = pathlib.Path(\"segmentation_stuff2\") / \"masks\"\n",
    "good_mask_names = np.array([path.name for path in tqdm(list(mask_dir.glob(\"*.tif\")))])[\n",
    "    good_indices\n",
    "]\n",
    "good_coeffs = coeffs[good_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c530ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "images = np.array(masks)[good_indices]\n",
    "flat_coeffs = good_coeffs.reshape((good_coeffs.shape[0], -1))\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "transformed_coeffs = np.ascontiguousarray(pca.fit_transform(flat_coeffs))\n",
    "\n",
    "good_imgs = [\n",
    "    tifffile.imread(f\"segmentation_stuff/masks/{pathlib.Path(p).name}\")\n",
    "    for p in tqdm(good_mask_names)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scale_morphology.scales import dashboard\n",
    "\n",
    "embeddable_imgs = [\n",
    "    dashboard.embeddable_image(i.astype(np.uint8) * 255) for i in tqdm(good_imgs)\n",
    "]\n",
    "\n",
    "\n",
    "colours = []\n",
    "\n",
    "\n",
    "def _colour(name):\n",
    "    name = name.lower()\n",
    "    if \"hom\" in name:\n",
    "        if \"ontogenetic\" in name:\n",
    "            return 0\n",
    "        return 1\n",
    "    if \"ontogenetic\" in name:\n",
    "        return 2\n",
    "    return 3\n",
    "\n",
    "\n",
    "for name in good_mask_names:\n",
    "    colours.append(str(_colour(name)))\n",
    "\n",
    "dashboard_df = pd.DataFrame(transformed_coeffs, columns=[\"x\", \"y\"])\n",
    "dashboard_df[\"image\"] = embeddable_imgs\n",
    "dashboard_df[\"colour\"] = colours\n",
    "dashboard_df[\"name\"] = good_mask_names\n",
    "\n",
    "dashboard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a4e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, save\n",
    "from bokeh.models import ColumnDataSource, HoverTool, CategoricalColorMapper\n",
    "from bokeh.resources import INLINE\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "factors = np.unique(dashboard_df[\"colour\"])\n",
    "mapper = CategoricalColorMapper(factors=factors, palette=f\"Category10_4\")\n",
    "\n",
    "datasource = ColumnDataSource(dashboard_df)\n",
    "fig = figure(\n",
    "    title=\"Test\", width=800, height=800, tools=\"pan, wheel_zoom, box_zoom, reset\"\n",
    ")\n",
    "\n",
    "fig.add_tools(\n",
    "    (\n",
    "        HoverTool(\n",
    "            tooltips=\"\"\"\n",
    "<div>\n",
    "    <div>\n",
    "        <img src=\"@image\" style=\"float: left; margin: 5px 5px 5px 5px;\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <span style=\"font-size: 17px; font-weight: bold;\">@name</span>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.scatter(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    source=datasource,\n",
    "    size=4,\n",
    "    color={\"field\": \"colour\", \"transform\": mapper},\n",
    "    legend_field=\"colour\",\n",
    ")\n",
    "\n",
    "for i, colour_value in enumerate(np.unique(dashboard_df[\"colour\"])):\n",
    "    group_points = dashboard_df[dashboard_df[\"colour\"] == colour_value][\n",
    "        [\"x\", \"y\"]\n",
    "    ].values\n",
    "\n",
    "    if len(group_points) >= 3:\n",
    "        hull = ConvexHull(group_points)\n",
    "\n",
    "        vertices = group_points[hull.vertices]\n",
    "\n",
    "        # Close the polygon by adding the first point at the end\n",
    "        vertices = np.vstack([vertices, vertices[0]])\n",
    "\n",
    "        hull_color = mapper.palette[i % len(mapper.palette)]\n",
    "        fig.patch(\n",
    "            x=vertices[:, 0],\n",
    "            y=vertices[:, 1],\n",
    "            alpha=0.2,\n",
    "            line_color=hull_color,\n",
    "            line_width=2,\n",
    "            fill_color=hull_color,\n",
    "        )\n",
    "\n",
    "filename = \"test_dashboard.html\"\n",
    "save(\n",
    "    fig,\n",
    "    filename=filename,\n",
    "    title=pathlib.Path(filename.replace(\".html\", \"\")).name,\n",
    "    resources=INLINE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scale_morphology.scripts.plotting import interpret_dimensions\n",
    "\n",
    "interpret_dimensions._plot_pca_importance(\n",
    "    good_coeffs, np.zeros(good_coeffs.shape[0], dtype=bool)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [np.sum(m) / 255 for m in tqdm(np.array(masks)[good_indices])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21ad45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sizes, transformed_coeffs[:, 0], \".\")\n",
    "plt.xlabel(\"Scale Size (pixels?)\")\n",
    "plt.ylabel(\"PC1\")\n",
    "plt.title(\"The first principal component corresponds tells us about size\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_dir = pathlib.Path(\"rabia\")\n",
    "plot_dir.mkdir(exist_ok=True)\n",
    "plt.savefig(plot_dir /\"sizes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5432235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "from skimage.draw import polygon\n",
    "\n",
    "\n",
    "def convex_hull_mask(mask_bool):\n",
    "    \"\"\"Rasterize the convex hull of foreground pixels into a mask.\"\"\"\n",
    "    ys, xs = np.nonzero(mask_bool)\n",
    "    pts = np.stack([xs, ys], axis=1)  # (x, y)\n",
    "    if pts.shape[0] < 3:\n",
    "        return mask_bool.copy(), 0.0\n",
    "    hull = ConvexHull(pts)\n",
    "    hull_xy = pts[hull.vertices]\n",
    "    rr, cc = polygon(hull_xy[:, 1], hull_xy[:, 0], shape=mask_bool.shape)\n",
    "    hull_mask = np.zeros_like(mask_bool, dtype=bool)\n",
    "    hull_mask[rr, cc] = True\n",
    "    return hull_mask, hull.volume  # hull.volume is 2D area\n",
    "\n",
    "\n",
    "def concavity_metrics(mask_bool):\n",
    "    area = float(mask_bool.sum())\n",
    "    if area == 0:\n",
    "        return dict(\n",
    "            solidity=np.nan,\n",
    "            concavity_frac=np.nan,\n",
    "            dent_max=np.nan,\n",
    "            dent_mean=np.nan,\n",
    "            dent_max_norm=np.nan,\n",
    "            concavity_area=np.nan,\n",
    "        )\n",
    "\n",
    "    hull_mask, hull_area = convex_hull_mask(mask_bool)\n",
    "    if hull_area == 0:\n",
    "        return dict(\n",
    "            solidity=np.nan,\n",
    "            concavity_frac=np.nan,\n",
    "            dent_max=np.nan,\n",
    "            dent_mean=np.nan,\n",
    "            dent_max_norm=np.nan,\n",
    "            concavity_area=np.nan,\n",
    "        )\n",
    "\n",
    "    # Area-based concavity\n",
    "    solidity = area / hull_area\n",
    "    return 1.0 - solidity\n",
    "\n",
    "\n",
    "concavity = [concavity_metrics(m == 255) for m in tqdm(np.array(masks)[good_indices])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3703b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(concavity, transformed_coeffs[:, 1], \".\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576aad49",
   "metadata": {},
   "source": [
    "[^1](#cite_ref-1):  F. P. Kuhl and C. R. Giardina, ‘Elliptic Fourier features of a closed contour’, Computer Graphics and Image Processing, vol. 18, no. 3, pp. 236–258, Mar. 1982, doi: 10.1016/0146-664x(82)90034-x. \n",
    "\n",
    "[^2](#cite_ref-2): N. MacLeod, 'PalaeoMath 101 part 25: the centre cannot hold II: Elliptic fourier\n",
    "analysis.' Palaeontol. Assoc. Newslett. 79, 29–43, 2012 http://go.palass.org/65a."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scale-morphology (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
