{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02feb135",
   "metadata": {},
   "source": [
    "Metadata\n",
    "====\n",
    "First, we'll find how many scales were manually edited (and how):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66afc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "parent_dir = pathlib.Path(\n",
    "    \"~/zebrafish_rdsf/Carran/Postgrad/Scale images from WT_spp1_sost/TIFs/segmentations\"\n",
    ").expanduser()\n",
    "assert parent_dir.exists()\n",
    "\n",
    "segmentation_paths = sorted([str(x) for x in parent_dir.glob(\"*.tif\")])\n",
    "f\"{len(segmentation_paths)} segmentations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f85080",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_seg_dir = parent_dir.parents[2] / \"segmentations_cleaned\"\n",
    "clean_seg_paths = [clean_seg_dir / pathlib.Path(p).name for p in segmentation_paths]\n",
    "\n",
    "for p in clean_seg_paths:\n",
    "    assert p.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in pairs of the clean/raw segmentations. Invert the clean ones (whoops) and check them against the raw; if they don't match, keep track of them...\n",
    "\"\"\"\n",
    "\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "scale_paths = [parent_dir.parent / p.name.replace(\"_segmentation.tif\", \".tif\") for p in clean_seg_paths]\n",
    "\n",
    "scale_imgs = []\n",
    "raw_segs = []\n",
    "clean_segs = []\n",
    "edited_names = []\n",
    "\n",
    "for scale_path, raw_seg_path, clean_seg_path in zip(\n",
    "    tqdm(scale_paths), segmentation_paths, clean_seg_paths\n",
    "):\n",
    "    clean_seg = tifffile.imread(clean_seg_path)\n",
    "    raw_seg = tifffile.imread(raw_seg_path) * 255\n",
    "\n",
    "    clean_segs.append(clean_seg)\n",
    "    raw_segs.append(raw_seg)\n",
    "\n",
    "    if (clean_seg == raw_seg).all():\n",
    "        scale_imgs.append(None)\n",
    "        continue\n",
    "\n",
    "    edited_names.append(clean_seg_path.name)\n",
    "    scale_imgs.append(tifffile.imread(scale_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Show the edited scales\n",
    "\"\"\"\n",
    "\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "\n",
    "def clear_seismic() -> colors.Colormap:\n",
    "    \"\"\"\n",
    "    Colormap that varies from clear to a colour\n",
    "    \"\"\"\n",
    "    c_blue = colors.colorConverter.to_rgba(\"blue\")\n",
    "    c_white = colors.colorConverter.to_rgba(\"white\", alpha=0)\n",
    "    c_red = colors.colorConverter.to_rgba(\"red\")\n",
    "    return colors.ListedColormap([c_blue, c_white, c_red], f\"clear2seismic\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(24, 24))\n",
    "\n",
    "names = [n for n in edited_names if n is not None]\n",
    "\n",
    "for axis, name in zip(axes.flat, names):\n",
    "    # Find the index where it lives in the list\n",
    "    i = 0\n",
    "    for p in scale_paths:\n",
    "        if p.name == name.replace(\"_segmentation.tif\", \".tif\"):\n",
    "            break\n",
    "        i += 1\n",
    "    axis.imshow(scale_imgs[i])\n",
    "    axis.imshow(clean_segs[i], alpha=0.5)\n",
    "    axis.imshow(\n",
    "        raw_segs[i] - clean_segs[i],\n",
    "        cmap=clear_seismic(),\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        interpolation=\"none\",\n",
    "    )\n",
    "\n",
    "    axis.set_title(\n",
    "        \"\\n\".join(textwrap.wrap(name, width=20)).strip(\".tif\").replace(\"_\", \" \"),\n",
    "        fontsize=8,\n",
    "    )\n",
    "    axis.set_axis_off()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scale_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need the non-clean masks any more\n",
    "del segmentation_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193bf0e5",
   "metadata": {},
   "source": [
    "Next we'll get some stats on the growth stages, sex, age, mutation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780eaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scale_morphology.scales import metadata\n",
    "\n",
    "df = metadata.df([str(x) for x in clean_seg_paths])\n",
    "\n",
    "# Replace NaN magnifications with -1\n",
    "df.loc[np.isnan(df[\"magnification\"]), \"magnification\"] = -1\n",
    "\n",
    "def plot_mdata(df):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(16, 4))\n",
    "    for axis, label in zip(axes, [c for c in df.columns if c != \"path\"]):\n",
    "        axis.hist(df[label], bins=25)\n",
    "        axis.set_title(label)\n",
    "    \n",
    "plot_mdata(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b5d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# count occurrences of each combination of \"age\" and \"sex\"\n",
    "\n",
    "# Plot the heatmap\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "for axis, label1, label2 in zip(\n",
    "    axes, [\"age\", \"sex\", \"growth\"], [\"sex\", \"growth\", \"age\"]\n",
    "):\n",
    "    heatmap_data = df.pivot_table(\n",
    "        index=label1, columns=label2, aggfunc=\"size\", fill_value=0\n",
    "    )\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt=\"d\", ax=axis, cbar=False)\n",
    "    axis.set_ylabel(label1)\n",
    "    axis.set_xlabel(label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6320d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "from tqdm.notebook import tqdm\n",
    "from scale_morphology.scales import efa, errors\n",
    "\n",
    "coeff_dump = pathlib.Path(\"carran_coeffs.npy\")\n",
    "\n",
    "if coeff_dump.is_file():\n",
    "    coeffs = np.load(coeff_dump)\n",
    "else:\n",
    "    n_edge_points, order = 300, 50\n",
    "    coeffs = []\n",
    "    for scale in tqdm(\n",
    "        [\n",
    "            tifffile.imread(path).astype(np.uint8) * 255\n",
    "            for path in tqdm(clean_seg_paths)\n",
    "        ]\n",
    "    ):\n",
    "        try:\n",
    "            coeffs.append(efa.coefficients(scale, n_edge_points, order))\n",
    "        except errors.BadImgError as e:\n",
    "            coeffs.append(np.ones((order, 4)) * np.nan)\n",
    "            print(f\"\\nError processing scale: {e}. NaN coeffs\")\n",
    "    coeffs = np.stack(coeffs)\n",
    "    np.save(coeff_dump, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sort values so that we get the right plotting order for our scatter plots\n",
    "\"\"\"\n",
    "\n",
    "flat_coeffs = coeffs.reshape((coeffs.shape[0], -1))\n",
    "nan_mask = np.isnan(flat_coeffs).any(axis=1)\n",
    "\n",
    "df_nan_removed = df[~nan_mask].copy()\n",
    "flat_coeffs_nan_removed = flat_coeffs[~nan_mask]\n",
    "\n",
    "df_nan_removed.sort_values(by=\"magnification\", inplace=True, ascending=True)\n",
    "df_nan_removed.sort_values(by=\"age\", inplace=True)\n",
    "df_nan_removed.sort_values(by=\"sex\", inplace=True, ascending=True)\n",
    "df_nan_removed[\"age\"] = df_nan_removed[\"age\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0bd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create some labels for the sex/age encoding\n",
    "\"\"\"\n",
    "\n",
    "mf_mask = df_nan_removed[\"sex\"] != \"?\"\n",
    "mf_df = df_nan_removed[mf_mask].copy()\n",
    "mf_coeffs = flat_coeffs_nan_removed[mf_mask]\n",
    "\n",
    "# Want these groups - M/F age 7/12/18/40\n",
    "groups = np.zeros(mf_coeffs.shape[0], dtype=int)\n",
    "\n",
    "groups[mf_df[\"sex\"] == \"M\"] += 8\n",
    "\n",
    "groups[mf_df[\"age\"] == \"12\"] += 1\n",
    "groups[mf_df[\"age\"] == \"18\"] += 2\n",
    "groups[mf_df[\"age\"] == \"40\"] += 4\n",
    "\n",
    "encoding = {\n",
    "    0: \"F7\",\n",
    "    1: \"F12\",\n",
    "    2: \"F18\",\n",
    "    4: \"F40\",\n",
    "    8: \"M7\",\n",
    "    9: \"M12\",\n",
    "    10: \"M18\",\n",
    "    12: \"M40\",\n",
    "}\n",
    "colours = {\n",
    "    0: \"lightcoral\",\n",
    "    1: \"indianred\",\n",
    "    2: \"brown\",\n",
    "    4: \"red\",\n",
    "    8: \"cornflowerblue\",\n",
    "    9: \"royalblue\",\n",
    "    10: \"darkblue\",\n",
    "    12: \"blue\",\n",
    "}\n",
    "\n",
    "# Check we've correctly encoded it\n",
    "mf_df.loc[:, \"age_sex_group\"] = groups\n",
    "for val, group in mf_df.groupby(\"age_sex_group\"):\n",
    "    sexes = group[\"sex\"].unique()\n",
    "    ages = group[\"age\"].unique()\n",
    "    assert len(sexes) == 1, (val, sexes, ages)\n",
    "    assert len(ages) == 1, (val, sexes, ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perform LDA\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda_coeffs = lda.fit_transform(mf_coeffs, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bdef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(28, 6))\n",
    "\n",
    "\n",
    "def clear2colour_cmap(colour) -> colors.Colormap:\n",
    "    \"\"\"\n",
    "    Colormap that varies from clear to a colour\n",
    "    \"\"\"\n",
    "    c_white = colors.colorConverter.to_rgba(\"white\", alpha=0)\n",
    "    c_black = colors.colorConverter.to_rgba(colour, alpha=0.5)\n",
    "    return colors.ListedColormap([c_white, c_black], f\"clear2{colour}\")\n",
    "\n",
    "\n",
    "for i, axis in enumerate(axes):\n",
    "    x = lda_coeffs[:, i]\n",
    "    y = lda_coeffs[:, i + 1]\n",
    "\n",
    "    # Grid for this pair\n",
    "    xmin, xmax = x.min(), x.max()\n",
    "    ymin, ymax = y.min(), y.max()\n",
    "    xx, yy = np.mgrid[xmin:xmax:200j, ymin:ymax:200j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "    handles = []\n",
    "    for g, label in encoding.items():\n",
    "        mask = groups == g\n",
    "        if mask.sum() < 2:\n",
    "            continue  # KDE needs at least 2 points\n",
    "\n",
    "        data = np.vstack([x[mask], y[mask]])\n",
    "        kde = gaussian_kde(data)\n",
    "        f = np.reshape(kde(positions).T, xx.shape)\n",
    "\n",
    "        axis.contourf(xx, yy, f, levels=15, cmap=clear2colour_cmap(colours[g]))\n",
    "        n = int(np.sum(mask))\n",
    "        handles.append(Patch(color=colours[g], label=f\"{label}, {n=}\"))\n",
    "\n",
    "        axis.scatter(*data, c=colours[g], s=5, marker=\"s\", linewidth=0.5, edgecolor=\"k\")\n",
    "\n",
    "    axis.set_title(f\"LD{i+1} vs LD{i+2}\")\n",
    "\n",
    "if handles:\n",
    "    axes[0].legend(handles=handles, loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    ")\n",
    "\n",
    "\n",
    "def per_class_separability(X, y, cv=5, random_state=42, in_sample: bool = False):\n",
    "    \"\"\"\n",
    "    per-class separability for LDA.\n",
    "\n",
    "    Returns a DataFrame with per-class ROC-AUC (OvR), PR-AUC (OvR),\n",
    "    recall, precision, support, and mean true-class posterior.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    classes = np.unique(y)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "    y_proba = np.zeros((len(y), len(classes)))\n",
    "    y_pred = np.empty(len(y), dtype=classes.dtype)\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        if in_sample:\n",
    "            test_idx = train_idx\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        lda.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "        # Align fold probabilities to a fixed class order\n",
    "        fold_classes = lda.classes_\n",
    "        align = np.array([np.where(fold_classes == c)[0][0] for c in classes])\n",
    "\n",
    "        proba = lda.predict_proba(X[test_idx])[:, align]\n",
    "        y_proba[test_idx] = proba\n",
    "        y_pred[test_idx] = classes[np.argmax(proba, axis=1)]\n",
    "\n",
    "    # One-vs-rest AUCs\n",
    "    y_bin = label_binarize(y, classes=classes)\n",
    "    auc_ovr = roc_auc_score(y_bin, y_proba, average=None)\n",
    "    ap_ovr = average_precision_score(y_bin, y_proba, average=None)\n",
    "\n",
    "    # Per-class precision/recall (hard predictions)\n",
    "    recall = recall_score(y, y_pred, labels=classes, average=None, zero_division=0)\n",
    "    precision = precision_score(\n",
    "        y, y_pred, labels=classes, average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    # Mean posterior for the true class (soft, interpretable as “confidence”)\n",
    "    true_post = np.array(\n",
    "        [y_proba[i, np.where(classes == y[i])[0][0]] for i in range(len(y))]\n",
    "    )\n",
    "    mean_true_post = np.array([true_post[y == c].mean() for c in classes])\n",
    "\n",
    "    support = np.array([(y == c).sum() for c in classes])\n",
    "\n",
    "    out = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"support\": support,\n",
    "                \"recall\": recall,  # “X% of the time we correctly pick this class”\n",
    "                \"precision\": precision,\n",
    "                \"roc_auc_ovr\": auc_ovr,  # threshold-free separability vs rest\n",
    "                \"ap_ovr\": ap_ovr,  # PR AUC (useful for imbalance)\n",
    "                \"mean_true_posterior\": mean_true_post,  # avg P(class | x) for true class\n",
    "            },\n",
    "            index=classes,\n",
    "        )\n",
    "        .sort_index()\n",
    "        .rename(index=encoding)\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Out-of-sample metrics\n",
    "per_class_separability(mf_coeffs, groups, cv=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7cc615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-sample metrics\n",
    "per_class_separability(mf_coeffs, groups, cv=5, random_state=42, in_sample=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scale-morphology (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
