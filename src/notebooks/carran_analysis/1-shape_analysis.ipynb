{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02feb135",
   "metadata": {},
   "source": [
    "Shape Analysis\n",
    "====\n",
    "This notebook runs through the shape analysis once the segmentation has been performed.\n",
    "\n",
    "First we'll get some stats on the metadata: growth stages, sex, age, mutation etc. from the filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5933d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "parent_dir = pathlib.Path(\n",
    "    \"~/zebrafish_rdsf/Carran/Postgrad/segmentations_cleaned\"\n",
    ").expanduser()\n",
    "assert parent_dir.exists()\n",
    "\n",
    "segmentation_paths = sorted([str(x) for x in parent_dir.glob(\"*.tif\")])\n",
    "f\"{len(segmentation_paths)} segmentations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d81c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scale_morphology.scales import metadata\n",
    "\n",
    "df = metadata.df([str(x) for x in segmentation_paths])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042fc22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Drop scales with missing data\n",
    "\"\"\"\n",
    "\n",
    "df = df[~df[\"no_scale\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If necessary, read in the scales from the RDSF and perform EFA on them.\n",
    "\n",
    "Otherwise read in the EFA coefficients from a cache\n",
    "\"\"\"\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.measure import euler_number\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "\n",
    "from scale_morphology.scales import efa\n",
    "from scale_morphology.scales.segmentation import largest_connected_component\n",
    "\n",
    "\n",
    "def load_scale_data(segmentation_path):\n",
    "    \"\"\"\n",
    "    Returns the cleaned segmentations\n",
    "    \"\"\"\n",
    "    scale = tifffile.imread(segmentation_path)\n",
    "    if euler_number(scale) != 1:\n",
    "        # Fill holes\n",
    "        scale = binary_fill_holes(scale)\n",
    "        # Remove small objects\n",
    "        scale = (largest_connected_component(scale) * 255).astype(np.uint8)\n",
    "\n",
    "        # It's possible we might have removed everything, so just make sure we haven't here\n",
    "        if euler_number(scale) != 1:\n",
    "            raise ValueError(f\"Got {euler_number(scale)=}\")\n",
    "\n",
    "    return scale\n",
    "\n",
    "\n",
    "coeff_dump = pathlib.Path(\"carran_coeffs.npy\")\n",
    "\n",
    "if coeff_dump.is_file():\n",
    "    coeffs = np.load(coeff_dump)\n",
    "\n",
    "else:\n",
    "    n_edge_points, order = 300, 50\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "        scales = np.array(\n",
    "            tqdm(\n",
    "                executor.map(load_scale_data, segmentation_paths),\n",
    "                total=len(scale_paths),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    coeffs = [efa.coefficients(scale, n_edge_points, order) for scale in tqdm(scales)]\n",
    "    coeffs = np.stack(coeffs)\n",
    "    np.save(coeff_dump, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f833b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "coeffs = scaler.fit_transform(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sort values so that we get the right plotting order for our scatter plots\n",
    "\"\"\"\n",
    "\n",
    "flat_coeffs = coeffs.reshape((coeffs.shape[0], -1))\n",
    "\n",
    "df.sort_values(by=\"magnification\", inplace=True, ascending=True)\n",
    "df.sort_values(by=\"age\", inplace=True)\n",
    "df.sort_values(by=\"sex\", inplace=True, ascending=True)\n",
    "\n",
    "# For the seaborn plotting - we want to encode as a categorical variable\n",
    "df[\"age\"] = df[\"age\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0bd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create some labels for the sex/age encoding\n",
    "\"\"\"\n",
    "\n",
    "mf_mask = df[\"sex\"] != \"?\"\n",
    "mf_df = df[mf_mask].copy()\n",
    "mf_coeffs = flat_coeffs[mf_mask]\n",
    "\n",
    "# Want these groups - M/F age 7/12/18/40\n",
    "groups = np.zeros(mf_coeffs.shape[0], dtype=int)\n",
    "\n",
    "groups[mf_df[\"sex\"] == \"M\"] += 8\n",
    "\n",
    "groups[mf_df[\"age\"] == \"12\"] += 1\n",
    "groups[mf_df[\"age\"] == \"18\"] += 2\n",
    "groups[mf_df[\"age\"] == \"40\"] += 4\n",
    "\n",
    "encoding = {\n",
    "    0: \"F7\",\n",
    "    1: \"F12\",\n",
    "    2: \"F18\",\n",
    "    4: \"F40\",\n",
    "    8: \"M7\",\n",
    "    9: \"M12\",\n",
    "    10: \"M18\",\n",
    "    12: \"M40\",\n",
    "}\n",
    "colours = {\n",
    "    0: \"lightcoral\",\n",
    "    1: \"indianred\",\n",
    "    2: \"brown\",\n",
    "    4: \"red\",\n",
    "    8: \"cornflowerblue\",\n",
    "    9: \"royalblue\",\n",
    "    10: \"darkblue\",\n",
    "    12: \"blue\",\n",
    "}\n",
    "\n",
    "# Check we've correctly encoded it\n",
    "mf_df.loc[:, \"age_sex_group\"] = groups\n",
    "for val, group in mf_df.groupby(\"age_sex_group\"):\n",
    "    sexes = group[\"sex\"].unique()\n",
    "    ages = group[\"age\"].unique()\n",
    "    assert len(sexes) == 1, (val, sexes, ages)\n",
    "    assert len(ages) == 1, (val, sexes, ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perform LDA\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda_coeffs = lda.fit_transform(mf_coeffs, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bdef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(28, 6))\n",
    "\n",
    "\n",
    "def clear2colour_cmap(colour) -> colors.Colormap:\n",
    "    \"\"\"\n",
    "    Colormap that varies from clear to a colour\n",
    "    \"\"\"\n",
    "    c_white = colors.colorConverter.to_rgba(\"white\", alpha=0)\n",
    "    c_black = colors.colorConverter.to_rgba(colour, alpha=0.5)\n",
    "    return colors.ListedColormap([c_white, c_black], f\"clear2{colour}\")\n",
    "\n",
    "\n",
    "for i, axis in enumerate(axes):\n",
    "    x = lda_coeffs[:, i]\n",
    "    y = lda_coeffs[:, i + 1]\n",
    "\n",
    "    # Grid for this pair\n",
    "    xmin, xmax = x.min(), x.max()\n",
    "    ymin, ymax = y.min(), y.max()\n",
    "    xx, yy = np.mgrid[xmin:xmax:200j, ymin:ymax:200j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "    handles = []\n",
    "    for g, label in encoding.items():\n",
    "        mask = groups == g\n",
    "        if mask.sum() < 2:\n",
    "            continue  # KDE needs at least 2 points\n",
    "\n",
    "        data = np.vstack([x[mask], y[mask]])\n",
    "        kde = gaussian_kde(data)\n",
    "        f = np.reshape(kde(positions).T, xx.shape)\n",
    "\n",
    "        axis.contourf(xx, yy, f, levels=15, cmap=clear2colour_cmap(colours[g]))\n",
    "        n = int(np.sum(mask))\n",
    "        handles.append(Patch(color=colours[g], label=f\"{label}, {n=}\"))\n",
    "\n",
    "        axis.scatter(*data, c=colours[g], s=5, marker=\"s\", linewidth=0.5, edgecolor=\"k\")\n",
    "\n",
    "    axis.set_title(f\"LD{i+1} vs LD{i+2}\")\n",
    "\n",
    "if handles:\n",
    "    axes[0].legend(handles=handles, loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    ")\n",
    "\n",
    "\n",
    "def per_class_separability(X, y, cv=5, random_state=42, in_sample: bool = False):\n",
    "    \"\"\"\n",
    "    per-class separability for LDA.\n",
    "\n",
    "    Returns a DataFrame with per-class ROC-AUC (OvR), PR-AUC (OvR),\n",
    "    recall, precision, support, and mean true-class posterior.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    classes = np.unique(y)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "    y_proba = np.zeros((len(y), len(classes)))\n",
    "    y_pred = np.empty(len(y), dtype=classes.dtype)\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        if in_sample:\n",
    "            test_idx = train_idx\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        lda.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "        # Align fold probabilities to a fixed class order\n",
    "        fold_classes = lda.classes_\n",
    "        align = np.array([np.where(fold_classes == c)[0][0] for c in classes])\n",
    "\n",
    "        proba = lda.predict_proba(X[test_idx])[:, align]\n",
    "        y_proba[test_idx] = proba\n",
    "        y_pred[test_idx] = classes[np.argmax(proba, axis=1)]\n",
    "\n",
    "    # One-vs-rest AUCs\n",
    "    y_bin = label_binarize(y, classes=classes)\n",
    "    auc_ovr = roc_auc_score(y_bin, y_proba, average=None)\n",
    "    ap_ovr = average_precision_score(y_bin, y_proba, average=None)\n",
    "\n",
    "    # Per-class precision/recall (hard predictions)\n",
    "    recall = recall_score(y, y_pred, labels=classes, average=None, zero_division=0)\n",
    "    precision = precision_score(\n",
    "        y, y_pred, labels=classes, average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    # Mean posterior for the true class (soft, interpretable as “confidence”)\n",
    "    true_post = np.array(\n",
    "        [y_proba[i, np.where(classes == y[i])[0][0]] for i in range(len(y))]\n",
    "    )\n",
    "    mean_true_post = np.array([true_post[y == c].mean() for c in classes])\n",
    "\n",
    "    support = np.array([(y == c).sum() for c in classes])\n",
    "\n",
    "    out = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"support\": support,\n",
    "                \"recall\": recall,  # “X% of the time we correctly pick this class”\n",
    "                \"precision\": precision,\n",
    "                \"roc_auc_ovr\": auc_ovr,  # threshold-free separability vs rest\n",
    "                \"ap_ovr\": ap_ovr,  # PR AUC (useful for imbalance)\n",
    "                \"mean_true_posterior\": mean_true_post,  # avg P(class | x) for true class\n",
    "            },\n",
    "            index=classes,\n",
    "        )\n",
    "        .sort_index()\n",
    "        .rename(index=encoding)\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Out-of-sample metrics\n",
    "per_class_separability(mf_coeffs, groups, cv=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7cc615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-sample metrics\n",
    "per_class_separability(mf_coeffs, groups, cv=5, random_state=42, in_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Do the LDA using different labels\n",
    "\"\"\"\n",
    "\n",
    "m18_mask = (df[\"sex\"] == \"M\") & (df[\"age\"] == \"18\")\n",
    "m18_df = df[m18_mask]\n",
    "m18_coeffs = coeffs[m18_mask]\n",
    "\n",
    "m18_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb556942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want these groups - onto/regen wt/omd\n",
    "assert set(np.unique(m18_df[\"mutation\"])) == {\"OMD\", \"WT\"}\n",
    "assert set(np.unique(m18_df[\"growth\"])) == {np.inf, 10}\n",
    "\n",
    "groups = np.zeros(len(m18_coeffs), dtype=int)\n",
    "\n",
    "groups[m18_df[\"growth\"] == np.inf] += 2\n",
    "groups[m18_df[\"mutation\"] == \"WT\"] += 1\n",
    "\n",
    "encoding = {0: \"Regen (10); OMD\", 1: \"Regen (10); WT\", 2: \"Onto; OMD\", 3: \"Onto; WT\"}\n",
    "colours = {0: \"blue\", 1: \"red\", 2: \"darkblue\", 3: \"lightcoral\"}\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda_coeffs = lda.fit_transform(m18_coeffs, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac346aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 6))\n",
    "\n",
    "for i, axis in enumerate(axes):\n",
    "    x = lda_coeffs[:, i]\n",
    "    y = lda_coeffs[:, i + 1 if i < 2 else 0]\n",
    "\n",
    "    # Grid for this pair\n",
    "    xmin, xmax = x.min(), x.max()\n",
    "    ymin, ymax = y.min(), y.max()\n",
    "    xx, yy = np.mgrid[xmin:xmax:200j, ymin:ymax:200j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "    handles = []\n",
    "    for g, label in encoding.items():\n",
    "        mask = groups == g\n",
    "        if mask.sum() < 2:\n",
    "            continue  # KDE needs at least 2 points\n",
    "\n",
    "        data = np.vstack([x[mask], y[mask]])\n",
    "        kde = gaussian_kde(data)\n",
    "        f = np.reshape(kde(positions).T, xx.shape)\n",
    "\n",
    "        axis.contourf(xx, yy, f, levels=15, cmap=clear2colour_cmap(colours[g]))\n",
    "        n = int(np.sum(mask))\n",
    "        handles.append(Patch(color=colours[g], label=f\"{label}, {n=}\"))\n",
    "\n",
    "        axis.scatter(*data, c=colours[g], s=5, marker=\"s\", linewidth=0.5, edgecolor=\"k\")\n",
    "\n",
    "    axis.set_title(f\"LD{i+1} vs LD{i+2}\")\n",
    "\n",
    "axes[0].legend(handles=handles)\n",
    "\n",
    "fig.suptitle(\"M18\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scale-morphology (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
