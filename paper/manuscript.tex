% This document probably won't compile if you're running it yourself from
% the git repo, since the images aren't committed and are just in my home
% directory. This is fine though - this document is just meant to be a
% skeleton for a write up. I'll send the relevant images via email to the
% right people...
\documentclass[11pt,a4paper,notitlepage]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{natbib}

\author{Richard Lane, Carran Johal, Rabia Sevil, Chrissy Hammond}
\title{
	Scale Shape Methods
}

\begin{document}
\maketitle

The code for this analysis is in the github.com/JGIBristol/scale\_morphology repository.

\section{Materials}
\begin{itemize}
	\item Stuff that happened in the lab
	\item Which fish we used
	\item How many we ended up with
	\item Imaging, staining etc.
	\item Flowchart of fishes
	\item I used the 878 scales in Carran/Postgrad/ALP\_WT\_flattened/
\end{itemize}

\section{Segmentation}
Here's a scale, and the associated segmentation mask:
\begin{figure}[h!]
	\centering
	\begin{minipage}{0.4\textwidth}
		\includegraphics[width=\textwidth]{imgs/scale.png}
	\end{minipage}
	\begin{minipage}{0.4\textwidth}
		\includegraphics[width=\textwidth]{imgs/clean_segmentation.png}
	\end{minipage}
	\caption{A scale and the associated segmentation mask.
		Original filename: 10M\_(4.0x)\_Osx\_mcherry\_GFP\_D10Reg\_Fish2\_D10reg\_scale010\_\_OSX\_mcherry
		\_GFP\_2021\_10\_months\_AL 10M\_(4.0x)\_Osx\_mcherry\_GFP\_D10Reg\_Fish2\_D10reg\_scale010\_\_
		OSX\_mcherry\_GFP\_2021\_10\_months\_ALP.}
\end{figure}

We segmented the scales out by first using an AI model, and then manually cleaning the resulting masks.

\subsection{Automated Segmentation}
We used the Segment Anything Model (SAM 2) [https://arxiv.org/abs/2408.00714] to segment the scale.
This model is promptable, which means we give it both the image to segment and some additional information
such as points or bounding boxes which are then used to inform the segmentation. This is useful for us - there's
often a bubble/hair/loose bit of dye in the image that the SAM model picks up. We can reduce the amount this happens
by prompting the model.

The scales in our dataset were all stained with ALP which gives them good contrast.
We developed a method to find a prompt for these scales - first we roughly segment the scale out, then we use this
rough segmentation to find the prompt.
The procedure for the rough segmentation is:
\begin{enumerate}
	\item Preprocess the scale by enhancing contrast and blurring
	\item Attempt to segment the scale out by mean thresholding (skimage.threshold\_mean)
	\item Remove any objects in this segmentation mask that are touching the border of the image
	\item Remove small objects via binary opening
	\item Fill holes
	\item Take the largest connected component in the mask
\end{enumerate}
This gives us an approximate segmentation mask for the scale. It isn't good enough to use for the analysis
(we often miss parts around the edge of the scale, especially when there's high contrast between the
exposed/embedded parts of the scale), but it is good enough to find our prompt.

We then use this rough segmentation to find the prompt. The prompt for the ALP scale segmentation has two components:
a set of points and a bounding box.
The set of points is found by randomly selecting points from the interior of the mask - we do this by running 100 binary erosions
on the mask, and then randomly choosing some points. The binary erosions ensure that we don't sample points on the very edge of the
mask, which are less likely to be correct.
The bounding box is found by simply finding the bounding box of the rough segmentation.

An example of the ALP scale prompt can be seen in Fig.~\ref{alp_prompt}:
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\textwidth]{imgs/prompt.png}
	\caption{The prompt fed into the SAM model.
		The bounding box and points help the model to segment the correct objet out of the image -
		note that there are bubbles around the scale that we do not want to pick up.\\
		Original filename:
		10M\_(4.0x)\_Osx\_mcherry\_D10reg\_Fish1\_D10reg\_scale003
		\_\_OSX\_mcherry\_GFP\_2021\_10\_months\_ALP.tif
	}
	\label{alp_prompt}
\end{figure}

We also tried to segment scales from confocal images. This is less tested, and we haven't used it for the rest of the analyis,
but the prompt here is simply that we take five points in the centre of the image (like the 5 on a die) and prompt
the model that these must be in the object. This is because we assume the scale is in the middle of the image.
The contrast is lower for the confocal images, so we can't do the same ALP prompt procedure as above.

The script for running the automated segmentation is at scripts/1-automatic\_segmentation.py in the git repo.

The resulting segmentations are in Carran/Postgrad/ALP\_WT\_flattened\_segmentations/.

\subsection{Cleaning Segmentations}
Sometimes the SAM model will pick up things that aren't the scale, or only segment out
parts of the scale. This happened around 10\% of the time for our data. To deal with this,
we wrote a script using napari[10.5281/zenodo.3555620]/python to create a GUI for cleaning the scale.
This can be seen in Fig.~\ref{napari}.
\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.8\textwidth]{imgs/napari_cleaning_gui.png}
	\caption{The segmentation cleaning GUI.}
	\label{napari}
\end{figure}

Cleaned segmentations are in Carran/Postgrad/flattened\_segmentations\_cleaned/.

\section{Elliptic Fourier Descriptors}
Now that we have segmented our scales, we can analyse their shape.
Since our scales are nice, simple shapes (they don't contain holes or any pathologies
like fractal edges or anything weird) we can fully describe their shape with a single
closed curve representing their boundaries. We will do this using Elliptic Fourier Analysis (EFA),
to express the shapes in terms of Elliptic Fourier Descriptors (EFDs).

The procedure for EFA is as follows:
\begin{itemize}
	\item Remove any spurious bits, fill holes - even the clean segmentations sometimes have issues like stray pixels
	\item Find equally spaced points around the edge of the segmentation using shapely [10.5281/zenodo.5597138].
	\item Re-order points such that we have a consistent ordering. (Otherwise two rotated but otherwise identical shapes will have different EFD descriptors.)
	      In my case, I reorder such that the first point is closest to the centre of mass of the object.
	\item Fit to these with pyefd [https://github.com/hbldh/pyefd] to find EFDs
\end{itemize}
The EFDs we extract are $4N$ floating-point numbers for N harmonics.
An illustration is in Figure.~\ref{efa_illustration}

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{imgs/efa_illustration.png}
	\caption{An illustration of the EFA procedure.
		Left: the segmentation with an elliptical fit to its edge in green. This is the first harmonic of the EFA expansion.
		Middle: the full EFA expansion up to 25 harmonics.
		Right: the EFA expansion up to 5 harmonics. Note that smaller features are not reproduced.
		Original image 12M\_(4.0x)\_LC3\_GFP\_Osx\_mcherry\_D10Reg\_Fish1\_female\_D10reg\_scale002\_\_2021
		\_LC3\_GFP\_OSX\_Mcherry\_1year\_ALP
	}
	\label{efa_illustration}
\end{figure}

The maths of EFA is briefly covered in Appendix~\ref{efa_maths}.

\section{Feature Extraction}
\begin{itemize}
	\item Features chosen:
	      \begin{itemize}
		      \item Size
		      \item Aspect Ratio
		      \item Bumpiness
		            \begin{itemize}
			            \item Why take the log? Because it makes it look right. Not taking the log squishes everything up to small values like 0.0001 vs 0.000001,
			                  the absolute difference between which isn't that descriptive - but the log-difference is.
			            \item Mathematical explanation: we take the log because we expect the Fourier power to decrease as (at least) some power law:
			                  \begin{itemize}
				                  \item the scale has finite area/perimiter/is bounded - this tells us that x is square-integrable, i.e. $\int_0^{2\pi}x(t)^2dt$.
				                  \item By Parseval's theorem, this means that $\sum_n^\infty(a_n^2 + b_n^2)$ (since the a, b coeffs came from the x points). Same for the $b, c$ coeffs from $y$.
				                  \item i.e. total harmonic power must converge - $\sum_{n=1}^\infty \left(a_n^2 + b_n^2 + c_n^2 + d_n^2 \right) < \infty$
				                  \item This tells us that the higher harmonics have to $\rightarrow 0$ as $n\rightarrow \infty$.
				                  \item How fast they decay is determined by smoothness - if the shape is continuous (but not differentiable, i.e. it has sharp corners) then
				                        our coefficients will decay as $1/n$.
				                  \item Further constraints (like having smooth, non-sharp corners or being analytic) will mean the coeffs decay even faster.
				                  \item For scales, we can at least say that the Fourier power per harmonic decays at least like $1/n^2$ (but probably faster).
				                  \item The bumpiness (fraction of power in higher harmonics) is:
				                        \begin{equation}
					                        \frac{\sum_n^{nmax} a_n^2}{\sum_1^{nmax} a_n^2}
				                        \end{equation}
				                  \item Taking the log of this, we get
				                        \begin{equation}
					                        log\left(\sum_n^{nmax} a_n^2\right) - log\left(\sum_1^{nmax} a_n^2\right)
				                        \end{equation}
				                  \item Since we expect these to decay as power-laws, we have turned our power-law variation into linear
				                        variation and turned multiplicative variation into additive variation (more intuitive)
				                  \item This is too much detail for the paper it's just interesting from an EFA perspective
			                  \end{itemize}
		            \end{itemize}
	      \end{itemize}
	\item[]
	\item Why not just use PCA - global variation instead of class separability, only linear, not biologically informed
\end{itemize}

\section{Statistical Tests + Interpreting Axes}
\begin{itemize}
	\item LDA explanation + sklearn citation
	\item LDA accuracy metrics
	\item Stats tests explanations - not too much detail
\end{itemize}


\appendix
\section{Calculating EFDs}
\label{efa_maths}
Given a set of points on our edge ${x, y}$ we parameterise our shape with EFDs as follows:

\begin{align}
	\begin{aligned}
		x(t) & = a_0 + \sum_{n=1}^{N} \big[a_n \cos(n t) + b_n \sin(n t)\big], \\
		y(t) & = c_0 + \sum_{n=1}^{N} \big[c_n \cos(n t) + d_n \sin(n t)\big],
		\qquad t \in [0, 2\pi].
	\end{aligned}
\end{align}

with:

\begin{align}
	\begin{aligned}
		a_0 = \frac{1}{2\pi}\int_{0}^{2\pi} x(t)\,dt,\qquad
		c_0 = \frac{1}{2\pi}\int_{0}^{2\pi} y(t)\,dt.
	\end{aligned}
\end{align}

\begin{align}
	\begin{aligned}
		a_n & = \frac{1}{\pi}\int_{0}^{2\pi} x(t)\cos(n t)\,dt, &
		b_n & = \frac{1}{\pi}\int_{0}^{2\pi} x(t)\sin(n t)\,dt,   \\
		c_n & = \frac{1}{\pi}\int_{0}^{2\pi} y(t)\cos(n t)\,dt, &
		d_n & = \frac{1}{\pi}\int_{0}^{2\pi} y(t)\sin(n t)\,dt.
	\end{aligned}
\end{align}

Our EFDs are N sets of $a_n, b_n, c_n, d_n$.
$a_0$ and $c_0$ encode the position of the edge (it is their centroid).

\section{EFA as a complete description of shape}
A note on EFD - a complete description of shape.
\begin{itemize}
	\item Normally people would just chuck things into PCA and hope for the best
	\item It will find the best linear* combinations that describe the dataset*
	\item This is fine
	\item There also seems to be a belief that PCA magically finds the right thing, and that you
	      might as well chuck your image pixels into PCA to find interesting features. This isn't true.
	\item We can come up with better (possibly non-linear, see the bumpiness metric below) features
	      that 1. actually describe the biologically interesting features in the dataset and
	      2. might never be picked up by pca (e.g. because they are non-linear, or because they don't describe
	      much global variation but do describe a lot of the difference between our classes).
	\item EFA is not a list of features derived from our shape - it is a *complete description of it* (down to some length scale)
	\item This means that ANY (reasonable) feature can be calculated from the EFA coefficients - it might be hard to work out how to do this, but it should be possible
	\item We show feature selection using EFDs here as an illustration - you could of course get e.g. size
	      by just counting pixels
\end{itemize}
\section{Mathematical notes on the bumpiness metric}

\end{document}
